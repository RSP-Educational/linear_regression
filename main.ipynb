{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ea8b615",
   "metadata": {},
   "source": [
    "<h1>Coding Session #1 - Lineare Regression</h1>\n",
    "\n",
    "Diese Datei ist ein Jupyter Notebook. Dieses besteht aus Textblöcken im Markdown Format und ausführbaren Code-Zellen. Diese erkennen Sie an dem kleinen Pfeilsymbol links daneben."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05aea99",
   "metadata": {},
   "source": [
    "## 1 Motivation\n",
    "\n",
    "Künstliche Neuronale Netze bestehen aus einer Vielzahl an Neuronen. Jedes Neuron ist in der Lage, eine simple mathematische Repräsentation zu lernen. Durch Verknüpfung mehrerer Neuronen können komplexe mathematische Funktionen nachgebildet werden. So kommen neuronale Netze in bspw. in der Bildverarbeitung, der Spracherkennung, für Wetter-, Energiebedarfs- oder Verschleißsprognosen zum Einsatz.\n",
    "\n",
    "## 2 Ziel\n",
    "\n",
    "Das Grundprinzip eines jeden Neurons ist **lineare Regression**. In diesem Coding Beispiel wird vorerst die Funktionsweise eines einzelnen Neurons betrachtet, bevor mehrere Neuronen zu einem neuronalen Netz verknüpft werden, um dessen Funktionsweise zu verdeutlichen.\n",
    "\n",
    "## 3 Vorbereitung\n",
    "\n",
    "Bei dieser Datei (`*.ipynb`) handelt sich um ein Jupyter Notebook. Das ist eine interaktive Datei, in der neben strukturierten Textzellen (`markdown`) Codezellen direkt integriert und ausgeführt werden können. Die Verwendung von `Visual Studio Code` wird empfohlen.\n",
    "\n",
    "### 3.1 Jupyter Extension installieren\n",
    "1. Klicken Sie auf Extensions<br>\n",
    "    <img src=\"images/vscode_extensions.png\" width=\"300px\"></img>\n",
    "2. Suchen Sie nach \"Jupyter\" und installieren Sie die Erweiterung.<br>\n",
    "    <img src=\"images/install_jupyter.png\" width=\"500px\"></img>\n",
    "\n",
    "### 3.2 Virtuelle Umgebung erstellen\n",
    "\n",
    "**Virtuelle Umgebungen** sorgen dafür, dass Paketinstallationen nur im lokalen Projektkontext (eben im virtuellen Environment) erfolgen. So werden Versionskonflikte mit bestehenden Installationen vermieden.\n",
    "\n",
    "**1.** Führen Sie im Terminal folgende Codezelle aus, um eine virtuelle Umgebung zu erstellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8b1541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3.12 -m venv .venv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b838657",
   "metadata": {},
   "source": [
    "**2.** Führen Sie je nach Betriebssystem eine der folgenden Zellen aus:\n",
    "\n",
    "Windows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9907c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!.\\.venv\\Scripts\\activate.bat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175db468",
   "metadata": {},
   "source": [
    "Linux & MacOS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26963518",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source .venv/bin/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1154535a",
   "metadata": {},
   "source": [
    "**3.1** Klicken Sie oben rechts in Visual Studio Code auf die Pathon Version<br>\n",
    "**3.2** Klicken Sie auf _Anderen Kernel auswählen..._\n",
    "   \n",
    "<img src=\"images/prepare001.png\" width=\"800px\"></img>\n",
    "\n",
    "**4.** Klicken Sie auf _Python Umgebungen..._\n",
    "   \n",
    "<img src=\"images/prepare002.png\" width=\"500px\"></img>\n",
    "\n",
    "**3.** Wählen Sie _.venv (Python 3.12.0)_\n",
    "\n",
    "<img src=\"images/prepare003.png\" width=\"500px\"></img>\n",
    "\n",
    "### 3.2 Requirements installieren\n",
    "\n",
    "Zur Vorbereitung stellen Sie bitte sicher, dass alle benötigten Bibliotheken installiert sind, indem Sie im folgende Zelle ausführen:<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5921f048",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f51aef",
   "metadata": {},
   "source": [
    "## 4 Code\n",
    "\n",
    "### 4.1 Daten Generierung\n",
    "\n",
    "Zuerst wird die Bibliothek `Numpy` importiert, welche fundamentale Funktionalitäten für numerische Berechnungen in Python bereitstellt.\n",
    "\n",
    "Anschließend werden Beispieldaten generiert. Dafür wird die vorgefertigte Funktion `generate_linear_data` aus der Datei `utilities/data.py` importiert und aufgerufen. Diese generiert Daten, die einer linearen Funktion $y=m\\cdot x+n$ folgen, wobei `m` der Anstieg, `n` die y-Verschiebung und `num_samples` die Anzahl der generierten Datenpunkte ist.\n",
    "\n",
    "Die vorgefertigten Funktionen `plot_data_points` und `plot_series` werden aus der Datei `utilities/visualization.py` importiert. Diese dienen der Visualisierung der Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b019cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                                  # Numpy is a fundamental package for numerical computations in Python\n",
    "from utilities.data import generate_linear_data                     # Custom module for generating linear data\n",
    "from utilities.visualization import plot_data_points, plot_series   # Custom module for visualizing 2D \n",
    "\n",
    "X, Y = generate_linear_data(\n",
    "    m           = 1,\n",
    "    n           = 0,\n",
    "    num_samples = 20\n",
    ")\n",
    "plot_data_points(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7603d7",
   "metadata": {},
   "source": [
    "Der Parameter `noise` fügt zufällig künstlich generiertes Rauschen zu den Daten hinzu. Da reale Daten meist nicht perfekt sind, wird dieses Rauschen hier durch Zufallswerte simuliert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8220fd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = generate_linear_data(\n",
    "    m           = 1.0,\n",
    "    n           = 0.0,\n",
    "    num_samples = 50,\n",
    "    noise       = 0.15\n",
    ")\n",
    "plot_data_points(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99d90f8",
   "metadata": {},
   "source": [
    "### 4.2 Lineare Regression\n",
    "\n",
    "Das Ziel neuronaler Netze ist es, eine Funktion zu finden, die die Daten möglichst gut repräsentiert. Wir starten hier eine einfache lineare Abhängigkeit durch eine lineare Regression zu approximieren. Das ist genau das, was in einem einzelnen Neuron passiert.\n",
    "\n",
    "#### 4.2.1 Daten generieren\n",
    "\n",
    "Zuerst wird der Datensatz generiert $D=(X,Y)$:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;$X$ ...Eingabedaten<br>\n",
    "&nbsp;&nbsp;&nbsp;$Y$ ...Zieldaten $\\to$ es soll gelernt werden, diese Daten in Abhängigkeit von $X$ vorherzusagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb0b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "m           = 0.7   # Anstieg der Geraden\n",
    "n           = 1.5   # y-Verschiebung der Geraden\n",
    "noise       = 0.1   # Rauschanteil\n",
    "\n",
    "X, Y = generate_linear_data(\n",
    "    num_samples     = 50,\n",
    "    m               = m,\n",
    "    n               = n,\n",
    "    noise           = noise\n",
    ")\n",
    "\n",
    "plot_data_points(input=X, target=Y, prediction=None, title=f\"Linear Data with noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439df3c6",
   "metadata": {},
   "source": [
    "#### 4.2.2 Stochastic Gradient Descent (SGD)\n",
    "\n",
    "Nun versuchen wir die Funktion $\\hat{y}=w\\cdot x+b$ so zu optimieren, dass sie die Daten möglichst gut abbildet. Dafür werden mittels **Gradient Descent Algorithmus** die freien Parameter $w$ und $b$ iterativ angepasst.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;$x$ ...x-Wert aus den Daten (`inputs`)<br>\n",
    "&nbsp;&nbsp;&nbsp;$y$ ...y-Wert aus den Daten (`targets`)<br>\n",
    "&nbsp;&nbsp;&nbsp;$w$ ...weight (zu lernender Anstieg, unbekannt)<br>\n",
    "&nbsp;&nbsp;&nbsp;$b$ ...bias (zu lernende y-Verschiebung, unbekannt)\n",
    "\n",
    "> ---\n",
    "> **Gradient Descent Algorithmus**\n",
    "> \n",
    "> ---\n",
    ">\n",
    "> **Eingaben:**\n",
    "> - Lernrate $\\eta$ (eta)\n",
    "> - Trainingsdaten $D = {(X,Y)}$\n",
    "> - Anzahl Epochen $E$\n",
    "> - Initiales weight $w\\leftarrow 0$\n",
    "> - Initialer Bias $b\\leftarrow 0$\n",
    ">\n",
    "> **Ausgaben**\n",
    "> - Vorhersage $Y$\n",
    "> \n",
    "> **for** $epoch = 1,\\,...,\\,E$ **do**<br>\n",
    ">> **for** $x_i,y_i\\in D$ **do**<br>\n",
    ">>> $\\hat{y_i} = w\\cdot x_i + b$<br>\n",
    ">>> $dw = 2 \\cdot (y_i-\\hat{y_i}) \\cdot x_i$<br>\n",
    ">>> $db = 2 \\cdot (y_i-\\hat{y_i})$\n",
    ">>>\n",
    ">>> $w\\leftarrow w - \\eta \\cdot dw$<br>\n",
    ">>> $b\\leftarrow b - \\eta \\cdot db$\n",
    ">>\n",
    ">> **end for**\n",
    ">\n",
    "> **end for**\n",
    ">\n",
    "> ---\n",
    "\n",
    "**Erklärung**\n",
    "\n",
    "Die lineare Regression minimiert die Summe der quadrierten Abweichungen zwischen tatsächlichen Werten $\\hat{y}$ und vorhergesagten Werten $y$, indem sie den quadratischen Fehler (Mean Square Error - MSE) minimiert.\n",
    "$$L_{MSE}=(y-\\hat{y})^2$$\n",
    "$$L_{MSE}=(y-(wx+b))^2$$\n",
    "\n",
    "Man startet mit zufälligen Parametern weight $w$ und bias $b$ und verbessert sie in kleinen Schritten, indem man die partielle Ableitung der Loss-Funktion nach $w$ und $b$ bildet und diese multipliziert mit der Lernrate $\\eta$ auf $w$ bzw. $b$ addiert:\n",
    "$$w \\leftarrow w - \\eta \\frac{\\partial Loss}{\\partial w}$$\n",
    "$$b \\leftarrow b - \\eta \\frac{\\partial Loss}{\\partial b}$$\n",
    "\n",
    "Die partiellen Ableitungen der MSE-Loss-Funktion sind hierbei\n",
    "$$\\frac{\\partial L_{MSE}}{\\partial w}=2\\cdot(wx+b-y)\\cdot x=2\\cdot(\\hat{y}-y)\\cdot x$$\n",
    "$$\\frac{\\partial{L_{MSE}}}{\\partial{b}}=2\\cdot(wx+b-y)=2\\cdot(\\hat{y}-y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f1bf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "EPOCHS      = 200       # Number of training epochs\n",
    "LR          = 0.001     # Learning Rate\n",
    "w, b        = 0., 0.    # weight and bias\n",
    "losses      = []        # to store loss values\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # prediction is a vector of target size, initialized with zeros\n",
    "    Y_hat = np.zeros_like(Y)\n",
    "\n",
    "    for i, (x, y) in enumerate(zip(X, Y)):\n",
    "        y_hat = w * x + b  # Linear model prediction\n",
    "\n",
    "        grad_w = 2 * (y_hat - y) * x\n",
    "        grad_b = 2 * (y_hat - y)\n",
    "\n",
    "        w -= LR * grad_w\n",
    "        b -= LR * grad_b\n",
    "\n",
    "        Y_hat[i] = y_hat\n",
    "\n",
    "    loss = np.mean((Y_hat - Y) ** 2)\n",
    "    losses.append(loss)\n",
    "\n",
    "    if (epoch+1) % 20 == 0 or epoch == 0 or epoch == EPOCHS - 1:\n",
    "        plot_data_points(input=X, target=Y, prediction=Y_hat, title=f\"Linear Data Fitting - Epoch {epoch+1}\")\n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS}, MSE: {loss:0.6f}\")\n",
    "\n",
    "plot_series(data=losses, title=\"Training Loss over Epochs\", xlabel=\"Epochs\", ylabel=\"MSE Loss\")\n",
    "print(f'Learned parameters: w = {w.flatten()[0]:.4f}, b = {b.flatten()[0]:.4f}, True parameters: m = {m}, n = {n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969200c8",
   "metadata": {},
   "source": [
    "Sie haben nun gelernt, wie ein einzelnes Neuron lernt. In Part 2 werden wir uns anschauen, wie dies in einem neuronalen Netz funktioniert."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
